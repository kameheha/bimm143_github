---
title: "Machine Learning 1"
author: "Victor Yu"
format: pdf
---

#First up kmeans ()

Demo ad using kmeans () function in base R. First make up some data with a known structure.

```{r}
#normal distribution of 10000 observations
#centered around 0
hist (rnorm (10000))
```


```{r}
#30 observations within +- 3
tmp <- c (rnorm(30, -3), rnorm (30,3) )

#x <- cbind(tmp,rev(temp))
#rev(tmp) puts +3 first, then -3

x <- cbind(x = tmp, y = rev (tmp))
head(x)

plot(x)
```

Now we have some made up data in `x` let's see how kmeans work with this data

```{r}
k <- kmeans(x, centers = 2, nstart = 20)
k
```
>Q. How many points are in each cluster

```{r}
k$size
```

>Q. How Do we get to the cluster membership/assignment.

```{r}
k$cluster
```

>Q. What about cluster centers.

```{r}
k$centers
```


No w we got to the main results let's use them to plot our data with the kmeans result
```{r}
plot (x, col = k$cluster)
points(k$centers, col = "blue", pch =15)
```

## Now for Hierarchical Clustering

We will cluster the same data `x` with the `hclust()`. In this case `hclust()` requires a distance matrix as input

```{r}
d <-  dist(x)
hc <- hclust( dist(x) )
hc
```

Let's plot our hclust result

```{r}
plot (hc)
```

To get our cluster memberhsip vector we need to "cut" the tree with the `cutree()`

```{r}
grps <- cutree(hc, h=10)
grps
```

Now plot our data with the hclust() results.

```{r}
plot(x, col = grps)
```

```{r}
#K = argument to cutree is a lot more helpful than the H, height
cutree(hc, k=1)
```

#Principle Componenet Analysis (PCA)

## PCA of UK food data

Read data from website and try a few visualizations. 

```{r}
url <- "https://tinyurl.com/UK-foods"
UK <- read.csv(url)
```

Q1. How many rows and columns are in your new data frame named x? What R functions could you use to
answer this questions?

```{r}
#setup / checking dimensiono of the data set
dim(UK)
head(UK)
```

```{r}
rownames (UK) = UK[,1]
UK <- UK[,-1]
dim (UK)
```

Q2.Which approach to solving the ‘row-names problem’ mentioned above do you prefer and why? Is one
approach more robust than another under certain circumstances?

Answer: I prefer the second method since it is uch more concise. All i have to do i to remember to add row.names = 1 then i save so much time

```{r}
barplot(as.matrix(UK), beside = T, col = rainbow (nrow(UK)))
```
Q3:  Changing what optional argument in the above barplot() function results in the following plot?

Answer: If you remove the beside optionor change it to false, the bar plot type changes.

Q5: Generating all pairwise plots may help somewhat. Can you make sense of the following code and
resulting figure? What does it mean if a given point lies on the diagonal for a given plot?

The colors in the figure correspond with a different food type. Each plot has a different corresponding 2 contries which makes up its X and Y axis.

```{r}
pairs(UK, col = rainbow(10), pch = 16)
```

Q6. What is the main difference between N. Ireland and the other countries of the uK in terms of this data-set?

N. Ireland diagnonal lines are not as a linear in comparison to the other countries. The dots are more spread out indicating increased variance.

PCA to the rescue!!
The main base R PCA function is called `prcomp()`

```{r}
#t(x) is the tranpose of the data. Test t(x) when you can't visuallize it yourself.
pca <- prcomp( t(UK) )
```

Summary of PCA data, on what it is doing
```{r}
summary(pca)
```

Q7. Complete the code below to generate a plot of PC1 vs PC2. The second line adds text labels over the
data points.

To make our new PCA plt (a.k.a PCA score plot) we access `pca$x`

```{r} 
#xlim sets the limits in the graph. Make it more aesthetic 
plot(pca$x [,1], pca$x[,2], xlab = "PC1", ylab = "PC2", xlim = c(-270, 500))
text(pca$x [,1], pca$x[,2], colnames(UK))
```

Q8. Customize your plot so that the colors of the country names match the colors in our UK and Ireland
map and table at start of this document.

Adding Color!

```{r}
#c is vector of colors. Keep in mind
country_cols <- c("orange", "red", "blue", "green")
plot(pca$x [,1], pca$x[,2], xlab = "PC1", ylab="PC2", col = country_cols)
text(pca$x [,1], pca$x[,2], colnames(UK),
col = country_cols)
```

```{r}
#variance colculation (must square standard dev. sdev^2)
v <- round( pca$sdev^2 / sum(pca$sdev^2) * 100)
v
```

```{r}
#Alternative, prints out sdev and variance and cumulation
x <- summary (pca)
x$importance
```

```{r}
#Bar plot calculating for variance
barplot(v, xlab= "Principal Component", ylab = "Percent Variation")

```

```{r}
#PC1 looking > 90% variance
par(mar=c(10, 3, 0.35, 0))
barplot (pca$rotation[,1], las=2)
```
Q9: Generate a similar ‘loadings plot’ for PC2. What two food groups feature prominantely and what does
PC2 maninly tell us about?

The two prominent food groups are fresh potatoes and soft drinks. The PC2 tells us variance of the y-axis.
```{r}
#PC2 looking > 90% variance
#Same code used in PC2 function
par(mar=c(10, 3, 0.35, 0))
barplot (pca$rotation[,2], las=2)
```

```{r}
#Big Plot Function
biplot(pca)
```
